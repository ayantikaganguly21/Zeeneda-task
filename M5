Question 1: What was the objective of Session 5 (System Interaction and Data Design)?
Answer:
The objective of Session 5 was to translate validated requirements into structured system interaction models, data definitions, and measurable KPI specifications. The session focused on building sequence diagrams to model system behavior, creating a data dictionary to eliminate ambiguity in data interpretation, and defining KPIs that are clear, testable, and implementable in reporting tools such as Power BI. The goal was to ensure that requirements are not only functionally correct but also dashboard-ready and test-ready. The session emphasized responsible AI usage as a drafting accelerator while ensuring all outputs are validated by human review.
Question 2: What is a Sequence Diagram and why is it important?
Answer:
A sequence diagram is a UML interaction diagram that shows how different participants such as users, systems, or services exchange messages over time. It models who communicates with whom and in what order. Sequence diagrams are important because they validate use cases end-to-end, reveal integrations and dependencies, define API calls or events, and help identify required data fields and system state changes. They are especially useful for requirements validation and QA test design because they clearly show expected system responses and interaction flow.
Question 3: What is the difference between a System Sequence Diagram (SSD) and a Design-Level Sequence Diagram?
Answer:
A System Sequence Diagram treats the system as a black box and focuses only on interactions between external actors and the system. It is stakeholder-friendly and used mainly for validating requirements. A Design-Level Sequence Diagram, on the other hand, shows internal system components such as services, databases, and APIs. It is more technical and useful for development alignment. The design-level diagram should be derived from the approved SSD to avoid over-specification or assumptions that are not validated.
Question 4: What is a Data Dictionary and why is it necessary?
Answer:
A data dictionary is a centralized reference document that defines metadata for each table and column, including business definition, data type, allowed values, constraints, nullability, example values, and relationships. It acts as a contract between business analysts, engineers, QA teams, and BI developers. A well-defined data dictionary prevents misinterpretation of data fields, supports consistent KPI calculations, and enables automated data quality checks. Without a data dictionary, different teams may interpret the same field differently, leading to reporting errors and rework.
Question 5: What data quality rules should be specified for maintenance work orders?
Answer:
Data quality rules should include uniqueness, completeness, validity, consistency, timeliness, and referential integrity. For example, work_order_id must be unique, priority must be limited to predefined values such as P1 to P4, mandatory fields must be completed before creation, created_at must be earlier than or equal to closed_at, and asset_id must exist in the Assets table. Status transitions must follow a defined workflow such as Open to In Progress to Closed. These rules ensure that KPIs and reports are based on reliable and consistent data.
Question 6: What makes a KPI usable and implementable?
Answer:
A usable KPI must answer a specific business question and have a single agreed definition. It must clearly state the formula, grain of measurement such as per work order or per asset, reporting period, filters or segments, and inclusion or exclusion criteria. It must also define how edge cases are handled, such as missing timestamps or downtime values. A good KPI is auditable, meaning the calculated value can be traced back to raw records without ambiguity.
Question 7: What KPIs were identified for the maintenance work order modernization case?
Answer:
Key KPIs included SLA compliance percentage, backlog count, MTTR (Mean Time to Repair), downtime minutes, MTBF (Mean Time Between Failures), and parts stockout rate. SLA compliance measures the percentage of work orders completed within the defined SLA target. Backlog measures the number of open work orders segmented by age buckets. MTTR measures the average repair time. Downtime minutes measure total operational downtime caused by issues. MTBF measures average time between failures per asset. Parts stockout rate measures the frequency of work orders delayed due to unavailable parts. Each KPI must be linked to clearly defined data fields in the data dictionary.
Question 8: What were the main deliverables of the Session 5 lab?
Answer:
The main deliverables included two sequence diagrams (a System Sequence Diagram and a zoom-in design-level diagram), a data dictionary excerpt covering at least two tables such as WorkOrders and SLAs, and a KPI specification sheet covering six KPIs. Additionally, documented assumptions and open stakeholder questions were required to maintain transparency. These artifacts ensured traceability from requirements to system interactions, from data fields to KPI calculations, and from objectives to measurable outcomes.
